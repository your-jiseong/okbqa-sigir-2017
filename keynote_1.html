<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="OKBQA 2016 : Open Knowledge Base and Question Answering Workshop at COLING">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>OKBQA 2016</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <!--a id="forkme_banner" href="https://github.com/okbqa-adm/coling2016.okbqa">View on GitHub</a-->

          <h1 id="project_title">OKBQA 2016</h1>
          <h2 id="project_tagline">Open Knowledge Base and Question Answering Workshop at COLING, <font color=gray><strong>December 11 2016 | Osaka, Japan</strong></font></h2>
          <div class="banner-buttons">
            <a class="button button-primary" href="index.html#program">
            <span class="icon icon-right chevron-right" style="color:white">Workshop Program</span>
            </a>
          </div>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <div id="mainnav">
        <ul>
        <li><a href="#Proceedings" title="Proceedings"><h5>Proceedings</a></li>
        <li><a href="index.html#motivation-and-description" title="Introduction"><h5>Introduction</a></li>
        <li><a href="index.html#invited-speakers" title="Invited Speakers"><h5>Invited Speakers</a></li>
        <li><a href="index.html#featured-speeches" title="Featured Speeches"><h5>Featured Talks</a></li>
        <li><a href="index.html#program" title="Program"><h5>Program</a></li>
        <li><a href="index.html#paper-submissions" title="Submissions"><h5>Submissions</a></li>
        <li><a href="index.html#topics" title="Topics of Interest"><h5>Topics of Interest</a></li>
        <li><a href="index.html#important-dates" title="Important Dates"><h5>Important Dates</a></li>
        <li><a href="index.html#organizers" title="Organising Committee"><h5>Organizing Committee</a></li>
        <li><a href="index.html#committee" title="Programme Committee"><h5>Programme Committee</a></li>
        <li><a href="index.html#contact-information" title="Contact Information"><h5>Contact Information</a></li>
        </ul>
      </div>


      <section id="main_content" class="inner">

      <h2>Keynote Speaker</h2>
      <h3>Sebastian Riedel</h3>



<div class="container-fluid">
    <div class="row">
      
      <div class="col-md-8">
        <p>
         
        
        </p>
      </div>
    </div>

  <div class="row">
      <div class="col-md-4">
        <img src="images/keynote_riedel.jpg" width="200"  style="padding-bottom:10px">
      </div>

      <div class="col-md-12">
        <hr/>
        <h4>Bio</h4>
        <p class="allign-justify">
         <strong>Sebastian</strong> is a Reader in the Department of Computer Science at University College London and leads the UCL Machine Reading group. He is an Allen Distinguished Investigator and received $1M award from the Paul Allen Foundation to 'move the needle' towards answering broad scientific questions in AI. He is a Marie Curie fellow, was a finalist for the Microsoft Research Faculty Award and received a Google Focused Research award. Sebastian is generally interested in the intersection of Natural Language Processing and Machine Learning, and particularly interested in teaching machines to read and to reason with what was read.
        </p>

        <h4>Website</h4>
        <a href="http://www.riedelcastro.org" target="_blank">http://www.riedelcastro.org</a>
        <hr/>

        <h4>Title</h4>
        <p class="allign-justify">
          <strong style="font-size:1.2em;">Inferbeddings: Reading, Reasoning and Programming with Vector Representations</strong>
        </p>

        <hr/>

        <h4>Abstract</h4>
        <p class="allign-justify">
          We want to build machines that read, and make inferences based on what was read. A long line of work in the field has focussed on approaches where language is converted (possibly using machine learning) into a symbolic and relational representation. A reasoning algorithm (such as a theorem prover) then derives new knowledge from this representation. This allows for rich knowledge to captured, but generally suffers from two problems: acquiring sufficient symbolic background knowledge and coping with noise and uncertainty in data. Probabilistic logics (such as Markov Logic) offer a solution, but are known to often scale poorly.

        </p>
        <p class="allign-justify">
          In recent years a third alternative emerged: deep and shallow neural networks that operate on low dimensional vector space embeddings.  Such approaches scale well and are robust to noise, but they raise their own set of questions: What type of inferences do they support? How can explicit background knowledge be injected into neural archictures? How can we provide “proofs” that justify predictions? In this talk I present some initial answers to these questions based on work we have developed recently. I will discuss how logic can be injected into embeddings and how neural networks can learn to simulate the behaviour of backward chaining theorem provers. I will also show how to train a model to generate better training data to train a neural network, and how we can neuralize a program interpreter that allows us to write partial programs that capture our procedural background knowledge, and learn the rest of the program from data.
        </p>
    </div>
  </div>
</div>



      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">OKBQA 2016 maintained by <a href="https://github.com/okbqa-adm">okbqa-adm</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>

